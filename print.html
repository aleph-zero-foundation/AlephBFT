<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AlephBFT</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Documentation of the Rust implementation of Aleph protocol">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="what_is_aleph_bft.html"><strong aria-hidden="true">1.</strong> What is AlephBFT?</a></li><li class="chapter-item expanded "><a href="how_alephbft_does_it.html"><strong aria-hidden="true">2.</strong> What is Aleph?</a></li><li class="chapter-item expanded "><a href="aleph_bft_api.html"><strong aria-hidden="true">3.</strong> API of AlephBFT</a></li><li class="chapter-item expanded "><a href="differences.html"><strong aria-hidden="true">4.</strong> Differences between Aleph and AlephBFT</a></li><li class="chapter-item expanded "><a href="internals.html"><strong aria-hidden="true">5.</strong> AlephBFT Internals</a></li><li class="chapter-item expanded "><a href="reliable_broadcast.html"><strong aria-hidden="true">6.</strong> Reliable Broadcast</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">AlephBFT</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h2 id="1-what-is-alephbft"><a class="header" href="#1-what-is-alephbft">1. What is AlephBFT?</a></h2>
<p>AlephBFT is a Rust implementation of the <a href="https://arxiv.org/abs/1908.05156">Aleph Consensus Protocol</a> that offers a convenient API allowing it to be easily applied to various problems. The prime application of AlephBFT is to be the consensus engine (sometimes called the &quot;finality gadget&quot;) of the <a href="https://alephzero.org/">Aleph Zero blockchain</a>.</p>
<h3 id="11-high-level-idea-of-what-alephbft-does"><a class="header" href="#11-high-level-idea-of-what-alephbft-does">1.1 High level idea of what AlephBFT does.</a></h3>
<p>From the high level perspective AlephBFT allows a set of <code>N</code> prespecified nodes to agree on an ordering of items arriving in some unreliable streams of data that these nodes locally observe. An illustrative example to have in mind here is when these nodes all observe a growing blockchain that does not have a built-in notion of finality, and would like to finalize blocks. Then the above mentioned &quot;streams of data&quot; are simply the advancing sequences of blockchain &quot;tips&quot; that each of the nodes sees. Note that in this (and in all the interesting examples), because of possible forks, or network delays, the data streams of individual nodes might not be consistent.
The goal of a consensus protocol, is to ensure consistency of the decisions, even though relying on an unreliable data source. Consequently, what AlephBFT produces is a single stream of data that &quot;combines&quot; all the individual streams of the <code>N</code> nodes and importantly <strong>is consistent</strong> among the nodes. Thus, in the example above, all the nodes would produce a unique sequence of <strong>finalized</strong> blocks (see also the corresponding <a href="aleph_bft_api.html#321-blockchain-finality-gadget">AlephBFT API section</a> for a more detailed description on how to use AlephBFT as a finality gadget for a blockchain).</p>
<h3 id="12-high-level-idea-of-alephbft-requirements"><a class="header" href="#12-high-level-idea-of-alephbft-requirements">1.2 High level idea of AlephBFT requirements.</a></h3>
<p>Let us index the nodes taking part in the protocol as <code>i = 0, 1, ..., N-1</code> and call them &quot;the committee&quot;, below we list some high-level requirements to be able to run AlephBFT among this nodes:</p>
<ol>
<li>The nodes are connected via a network (that is not assumed to be 100% reliable) allowing them to send arbitrary messages to each other,</li>
<li>Each node knows the identities of all other nodes (via their public keys) and holds a private key allowing it to sign messages.</li>
<li>Each node <code>i</code> holds a data source object (to be explained in detail in the <a href="aleph_bft_api.html#311-dataio">DataIO subsection of AlephBFT API section</a> -- see <code>DataIO</code>) that allows it 1) to receive fresh pieces of data (we refer to it as the input stream <code>in_i</code>), and 2) to check that a piece of data received from another node is &quot;available&quot;. The availability is best understood when thinking about the blockchain example and data being block hashes. Then the availability question for a blockhash is essentially whether we locally hold a block with such a hash.</li>
<li>At most <code>(N-1)/3</code> of the nodes can be malicious (act with the intent to break the protocol guarantees).</li>
</ol>
<h3 id="13-high-level-idea-of-alephbft-guarantees"><a class="header" href="#13-high-level-idea-of-alephbft-guarantees">1.3 High level idea of AlephBFT guarantees.</a></h3>
<p>AlephBFT guarantees (as long as at most <code>(N-1)/3</code> nodes act maliciously) that each node <code>i</code> running the protocol produces a stream of data <code>out_i</code> such that:</p>
<ol>
<li>The output streams of any two nodes <code>out_i</code> and <code>out_j</code> are consistent, in the sense that at any given time one is a prefix of another. Moreover, none of the streams gets &quot;stuck&quot;, they keep producing items until the protocol is shut down. So, intuitively, all the streams produce the same items, but just at possibly different paces.</li>
<li>Each item in the output stream is &quot;available&quot; to at least half the honest (= not malicious) nodes in the committee.</li>
<li>Roughly speaking, all of the data items &quot;proposed&quot; by honest nodes (i.e., data coming from <code>in</code> streams of honest nodes) eventually land in the output stream.</li>
</ol>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="2-how-alephbft-does-it"><a class="header" href="#2-how-alephbft-does-it">2 How AlephBFT Does it?</a></h2>
<p>AlephBFT implements <a href="https://arxiv.org/abs/1908.05156">Aleph Consensus Protocol</a> -- we highly encourage you to read the original paper, as it offers the best explanation of the ideas and does not require much background to understand. In this documentation we try to offer a self-contained sketch of the protocol, although, because of its compactness it might be harder to understand. For those who have read the paper we would like to note that there are certain minor differences between the paper and the actual implementation that we highlight in a <a href="differences.html">dedicated section</a>. However, these do not affect any of the fundamental ideas behind AlephBFT or its security guarantees and are mostly tricks and implementation details.</p>
<p><strong>Note:</strong> for clarity, given <code>N</code> we define <code>f</code> to be the maximum number of malicious nodes allowed in AlephBFT: <code>f=floor(N-1)/3</code>. For instance, for <code>N</code>'s equal to <code>(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</code> the corresponding <code>f</code>s are <code>(0,0,0,1,1,1,2,2,2,3)</code>. Then the number of honest nodes is guaranteed to be at least <code>N-f = floor(2*N/3)+1</code> which is strictly more than <code>2*f</code>.</p>
<h3 id="21-dag----the-main-idea-of-alephbft"><a class="header" href="#21-dag----the-main-idea-of-alephbft">2.1 Dag -- the main idea of AlephBFT.</a></h3>
<p>Recall that in the model we are interested in, the nodes keep receiving new data items from their input streams <code>in_i</code> and would like to produce a single output stream <code>out</code> (i.e., the unique stream consistent with their local output streams <code>out_i</code>). The main idea of AlephBFT is for the nodes to produce a <strong>DAG</strong> (Directed Acyclic Graph) of vertices that we call <strong>Units</strong> where each such unit is created by one of the nodes <code>i</code> and carries one piece of data from the input stream <code>in_i</code>. Whenever a unit is created by a node <code>i</code> it is then dispersed among all other nodes with the intention that each node at any given time has a sufficiently up-to-date version of the Dag. AlephBFT then specifies a combinatorial algorithm that given a Dag <code>D</code> allows to compute (statically, without any need for communication) a certain prefix of the output stream <code>out</code>, with the property that as the Dag <code>D</code> is updated with new vertices to form <code>D'</code> then the new prefix computed out of <code>D'</code> is either the same or <strong>extends</strong> the one obtained from <code>D</code>. In other words, by growing the Dag, we cannot &quot;roll back&quot; the output sequence.</p>
<h3 id="22-constructing-the-dag----units"><a class="header" href="#22-constructing-the-dag----units">2.2 Constructing the Dag -- Units.</a></h3>
<h4 id="221-unit-structure"><a class="header" href="#221-unit-structure">2.2.1 Unit Structure.</a></h4>
<p>The structure of the Dag in the AlephBFT implementation is especially simple (some simplification here w.r.t. to the <a href="https://arxiv.org/abs/1908.05156">Aleph Paper</a>). Each unit <code>U</code> (vertex in the Dag) holds the following fields:</p>
<ol>
<li>The <code>creator</code> of <code>U</code> is simply a node index in <code>[0, N-1]</code> specifying who created this unit.</li>
<li>The <code>data</code> in <code>U</code> is an element of some <code>Data</code> type -- this is supposed to be the most recent data item <code>U.creator</code> received from its input stream prior to creation of <code>U</code>.</li>
<li>The <code>round</code> of <code>U</code> is a non-negative integer specifying the sequential number of the unit among the ones created by <code>U.creator</code>. It is convenient to think that <code>round</code> can be arbitrarily large, but for technical reasons it is bounded by a fixed constant <code>MAX_ROUND</code>.</li>
<li>The <code>parent_map</code> of <code>U</code> is a map of length <code>N</code> that specifies the rounds of parent units created by the committee members <code>{1, 2, ..., N}</code>. The meaning of this set is that if <code>i</code> is associated with round <code>r</code>in the <code>parent_map</code> then <code>U</code> has an edge to a unit <code>V</code> created by <code>i</code> in round <code>r</code>.</li>
<li>The <code>control_hash</code> of <code>U</code> or rather of parents of <code>U</code> is a fingerprint of the list of actual units being parents of <code>U</code>. While AlephBFT protocol instructs honest nodes to create exactly one unit per each round, this behavior cannot be enforced among malicious nodes. This is the reason why the <code>parent_map</code> array by itself does not necessarily uniquely specify the parents of <code>U</code> and we thus attach a <code>control_hash = Hash(U_1, U_2, ..., U_k)</code> where <code>U_1, ..., U_k</code> are the parents of <code>U</code>.</li>
<li>The <code>signature</code> is a signature under the unit (as a collection of all the above fields) generated by <code>U.creator</code>. The signature is a proof that a given node indeed created such a unit, all units must be sent along with signatures.</li>
</ol>
<p>By <code>parents(U)</code> we denote the set of all units that <code>U</code> has edges to (these are always units of round at least one less than <code>U</code>'s round). By <code>Hash(U)</code> we mean the hash of a serialization of the fields of <code>U</code> not including the <code>signature</code>. Since <code>Hash(U)</code> is smaller than <code>U</code> and still uniquely specifies <code>U</code> we sometimes use hashes in the protocol instead of units.</p>
<h4 id="222-unit-creation-rules"><a class="header" href="#222-unit-creation-rules">2.2.2 Unit Creation Rules.</a></h4>
<p>Below we provide a pseudocode for creating units that the honest nodes are expected to follow. In what follows <code>D</code> is the local copy of the Dag, i.e., the set of units that a particular node holds. We assume that a node can add a unit to <code>D</code> only if <code>parents(U)</code> are all in <code>D</code> (this requirement of course creates some challenges in the implementation, but we disregard them here).</p>
<pre><code>/* Written from the perspective of node k.  D is a global variable denoting the set of units held by k. */
def can_create(r):
	if round == 0:
		return true
	if D does not contain a unit created by k in round r-1:
		return false
	if D contains less than N-f units from different creators in round r-1:
		return false
	return true

def creator_task():
for r = 0, 1, 2, ...:
	loop:
		//since D is growing, the below if will eventually fire
		if can_create(r):
			Create a unit U of round r:
				Pick as its parents at least N-f units (from different creators) of round (r-1), including node k previous unit. Add the highest known units by all other creators.
				Poll the input stream for a fresh data item `d` and place it in `U` in the `data` field
			Send U to all other nodes
			sleep(CREATE_DELAY)
			break the inner loop
</code></pre>
<p>The <code>creator_task</code> keeps creating units of growing rounds, with the requirement that, roughly, there are at least <code>(2/3)*N</code> units in the previous round available in <code>D</code>. There is a certain delay after each unit is created -- this technicality allows us to make sure the Dag does not grow too quickly, which is problematic for pragmatic reasons: the nodes have limited bandwidth (which also varies between different nodes) and have bounded RAM memory, where we would like to store the Dag.</p>
<h4 id="223-malicious-units-forks-equivocations"><a class="header" href="#223-malicious-units-forks-equivocations">2.2.3 Malicious Units: Forks (Equivocations).</a></h4>
<p>Note that from the pseudocode of the <code>creator_task</code> it follows that each node is supposed to create exactly one unit per round, so ideally a Dag of &quot;height&quot; <code>R</code> should have <code>R*N</code> units in total. In the version of the AlephBFT protocol that is described in the main body of the <a href="https://arxiv.org/abs/1908.05156">paper</a>, this rule (one unit per node, per round) is enforced via a special broadcast protocol: Reliable Broadcast for disseminating units among other nodes. Roughly speaking, it guarantees that there will always be at most one unit per creator, per round. This is extremely convenient for making the protocol simple and clean, but unfortunately implementing the protocol this way (with reliable broadcast, which is quite heavy) is rather inefficient. For this reason AlephBFT implements a version of the protocol (referred to as <em>QuickAleph</em> in the <a href="https://arxiv.org/abs/1908.05156">paper</a>) that &quot;allows&quot; malicious nodes to create multiple versions of a unit for a given round (we call these forks). This makes the protocol slightly more complex, but much more efficient in practice. One can think of QuickAleph as an &quot;optimistic&quot; version of Aleph that assumes that all nodes typically behave honestly and fork only in extremely rare cases, at which time the protocol, in a sense, falls back to Reliable Broadcast in order to alert all the nodes that a forker has been detected (we give a little more details on that in the section on <a href="reliable_broadcast.html##6-reliable-broadcast">Reliable Broadcast</a>).</p>
<h4 id="224-disseminating-units"><a class="header" href="#224-disseminating-units">2.2.4 Disseminating Units.</a></h4>
<p>From now on we assume that whenever a unit <code>U</code> lands in a Dag <code>D</code> of an honest node <code>k</code> then all other honest nodes will eventually (maybe after some delay) receive <code>U</code> and place it in their copies of the Dag. To achieve this in practice there are several mechanisms in AlephBFT to guarantee robustness of the process of disseminating units:</p>
<ol>
<li>Firstly, the creator broadcasts the unit.</li>
<li>Secondly, all nodes periodically broadcast top known units for all other nodes. This only happens if a node didn't produce a unit for some time, because otherwise we can assume that other nodes received the newest unit in a regular broadcast.</li>
<li>Thirdly, there is a request-response mechanism that allows nodes to fetch missing units from other nodes.</li>
</ol>
<h3 id="23-computing-the-ordering-from-dag"><a class="header" href="#23-computing-the-ordering-from-dag">2.3 Computing the Ordering from Dag.</a></h3>
<p>So far (in Section 2.2) we learned that the main object in AlephBFT is the ever-growing Dag composed of units created by different nodes. We ensure (and thus assume this from now on) that all the honest nodes, at every moment in time, hold a reasonably up-to-date version of the Dag. We now proceed to describe an algorithm <code>OrderData</code>, which given a Dag <code>D</code> (a static object), computes a sequence (for instance <code>Vec&lt;Data&gt;</code> in Rust) of Data items (coming from some units in the Dag) which has the following fundamental <strong>monotonicity</strong> property:</p>
<p><strong>If <code>D</code> is a subset of <code>D'</code> then <code>OrderData(D)</code> is a prefix of <code>OrderData(D')</code>.</strong></p>
<p>Let us pause for a minute to realize how strong the property is, and that it already solves the consensus problem. Let us denote by <code>D_1</code>, <code>D_2</code>, ..., <code>D_N</code> the local Dags of nodes <code>1, 2, ..., N</code>, and by <code>order_1</code>, <code>order_2</code>, ..., <code>order_N</code> the results of applying the <code>OrderData</code> algorithm to these Dags. Further let <code>D</code> be the dag being the union of all <code>D_i</code>'s for <code>i=1, 2, ..., N</code>. From the property above it follows that if <code>order = OrderData(D)</code> then each <code>order_i</code> is a prefix of <code>order</code>, and hence consequently <code>order_i</code> also agree with each other! Given now such an algorithm <code>OrderData</code> we can complete the description of the AlephBFT protocol: each node simply keeps its local dag <code>D</code> up-to-date and recomputes <code>OrderData(D)</code> over and over, the ever-growing sequence of Data items obtained from this procedure is this node's output stream.</p>
<p><strong>Note:</strong> <em>The description of <code>OrderData</code> provided below is nowhere near to what happens in AlephBFT's code. This description is optimized for ease of understanding the main concept. An efficient implementation of the idea is another pair of shoes. In fact, the name <code>OrderData</code> is not even used in the code -- the ordered data instead lands in an output stream that is produced asynchronously.</em></p>
<p>Before we dive into the details and the pseudocode, let us first sketch an overall picture of what is going to happen in <code>OrderData</code>. First of all, there is a procedure of choosing a <code>Head</code> for each round in the Dag -- it essentially picks a single unit out of each round. The heads are then used to order all the units in the Dag: simply go over all the rounds <code>r=0, 1, 2, ...</code> and place the head <code>head_r</code> for this round along with all the units &quot;below&quot; the head that have not been ordered yet in a new batch. To choose heads we use virtual voting: the idea is that for each unit <code>U</code> in the dag, the units with round <code>&gt;= U.round</code> cast virtual &quot;votes&quot; (computed deterministically from the dag structure) on whether <code>U</code> should be chosen as head or not. The voting rules are crafted in such a way that at a certain round (typically round 3 or 4) above <code>U</code>, all units votes are already unanimous: either all vote &quot;yes&quot; or all vote &quot;no&quot;. This determines the &quot;decision&quot; for <code>U</code>. Then the head for a given round is chosen to be the first unit in the round (according to some deterministic ordering) that was decided as &quot;yes&quot;. We strongly encourage the reader to inspect the <a href="https://arxiv.org/abs/1908.05156">paper</a> for more intuitions.</p>
<h4 id="231-description-of-orderdata"><a class="header" href="#231-description-of-orderdata">2.3.1 Description of OrderData.</a></h4>
<p>For a unit <code>U</code> in a certain dag let us denote by <code>below(U)</code> the set of all units that can be reached from <code>U</code> by following 0 or more forward edges from <code>U</code>, so this set consists of <code>U</code>, parents of <code>U</code>, parents of parents of <code>U</code>, and so on. Below we describe <code>OrderData(D)</code> based on a procedure <code>Head(r, D)</code> that given a round <code>r</code> and dag <code>D</code> outputs an element of type <code>Option&lt;Unit&gt;</code> thus either <code>None</code> or <code>Some(U)</code> where <code>U</code> is some unit in <code>D</code> of round <code>r</code>. The description of <code>Head(r, D)</code> follows later.</p>
<pre><code>def OrderData(D):
	order = []
	batch = []
	for r = 0, 1, 2, ... :
		let head = Head(r, D)
		if head is None:
			break
		let Some(U) = head
		new_batch = below(U)
		remove from new_batch the contents of batch[0], batch[1], ..., batch[r-1]
		sort new_batch using any canonical ordering
		batch[r] = new_batch
		let [U_1, U_2, ..., U_k] = new_batch
		order = order ++ [U_1.data, U_2.data, ..., U_k.data]
	return order
</code></pre>
<p>The <code>OrderData</code> algorithm is indeed quite simple: we choose a <code>Head</code> unit from each consecutive round (until it is no more possible) and generate a new batch of units, by taking all units below the head, and removing units from previous batches. The ordering is simply the data items from the units in subsequent batches, where each batch is ordered arbitrarily (yet using some deterministic ordering). It is not hard to observe that <code>OrderData</code> has the desired monotonicity property as long as the black-box <code>Head(r, D)</code> is also &quot;monotone&quot;, in the sense that:</p>
<p><strong>If <code>D</code> is a subset of <code>D'</code> and <code>Head(r, D)=Some(U)</code> then <code>Head(r, D')=Some(U)</code>.</strong></p>
<p>We proceed to describing <code>Head(r, D)</code></p>
<h4 id="232-description-of-head"><a class="header" href="#232-description-of-head">2.3.2 Description of Head.</a></h4>
<p>We will again describe <code>Head</code> as a procedure using another black-box: <code>Decide(U, D)</code> which takes a unit <code>U</code> and a dag <code>D</code> and outputs a value of type <code>Option&lt;bool&gt;</code>, so either a boolean &quot;decision&quot; <code>Some(b)</code> or <code>None</code>. We assume here that <code>Decide(U, D)</code> satisfies an analogous property to the one mentioned for <code>Head</code> above.</p>
<pre><code>def Head(r, D):
	if the highest round of a unit in D is &lt; (r+3):
		return None
	let [U_1, U_2, ..., U_s] be the units in D of round r sorted according to some canonical order
	// The order is allowed to depend on r and on Head(r-1, D)
	for l = 1, 2, ..., s:
		if Decide(U_l, D) == Some(b):
			if b==true:
				return Some(U_l)
			else:
				continue the loop
		else:
			return None
	// The execution can never reach this line because at least one unit in round r must be decided true.
</code></pre>
<p>To compute the head for a given round <code>r</code> we test all the units of this round in the dag <code>D</code> in some arbitrary canonical order (ordering by unit hashes is fine, but more sophisticated orderings here might give additional defense against delays caused by malicious nodes). The first unit that is decided <code>true</code> in this list is decided to be the head, however if <code>Decide()</code> outputs <code>None</code> at any time, <code>Head</code> must output <code>None</code> as well.</p>
<h4 id="233-description-of-decide"><a class="header" href="#233-description-of-decide">2.3.3 Description of Decide.</a></h4>
<p>Finally we describe the <code>Decide</code> procedure which is the last remaining piece to have a working consensus protocol. Again, <code>Decide</code> is based on a black-box <code>DecideVia(U, V, D)</code> which we describe subsequently:</p>
<pre><code>def Decide(U, D):
	if there exists any unit V in D such that DecideVia(U, V, D) == Some(b):
		// In this case it is guaranteed that all bs will be the same
		return Some(b)
	else:
		return None
</code></pre>
<p>To explain <code>DecideVia</code> we first need to define &quot;virtual voting&quot; (we refer to the <a href="https://arxiv.org/abs/1908.05156">paper</a> for intuitions and clarifications) -- intuitively, the units that are &quot;beyond U&quot; (i.e. have higher round number) &quot;vote&quot; for whether we should decide <code>true</code> or <code>false</code> for <code>U</code>. It is good to think that this vote decides, whether &quot;<code>U</code> is well known among nodes&quot;. We again emphasize that the decision for <code>U</code> depends on the static structure of the dag <code>D</code> only and except from them impact <code>U.creator</code> had on the shape of <code>D</code> he cannot affect the decision in any other way.</p>
<pre><code>def Vote(U, V, D):
	// It is assumed that V.round &gt; U.round
	round_diff = V.round - U.round
	if round_diff == 1:
		return [U belongs to parents(V)]
	else:
		let votes be the multiset of Vote(U, P, D) for P in parents(V)
		if votes are all the same, and equal to b:
			return b
		else:
			return CommonVote(round_diff)

def CommonVote(round_diff):
	if round_diff &lt;= 4:
		if round_diff == 3:
			return false
		else:
			return true
	else:
		return [(round_diff % 2) == 1]

def DecideVia(U, V, D):
	round_diff = V.round - U.round
	if round_diff &lt; 3:
		return None
	threshold = N-f
	cv = CommonVote(round_diff)
	let votes be the multiset of Vote(U, P, D) for P in parents(V)
	if among votes there are &gt;= threshold votes equal to cv:
		return Some(cv)
	return None
</code></pre>
<p>We are not going into details here why the above guarantees the kind of monotonicity properties that we defined above. For that we refer to the paper, let us however offer a quick argument why we should expect consistency among decisions. The idea here is that once the condition in <code>DecideVia</code> is satisfied, i.e., among parent votes there is at least <code>threshold</code> of them that agree with the CommonVote <code>cv</code>, then one can easily prove that starting from the next round, all units are going to vote for <code>cv</code>. Once that happens, it is easy to see that each unit beyond that will make a decision consistent with <code>cv</code>. For proper proofs we refer to the Appendix of the paper.</p>
<h3 id="24-randomness-in-alephbft"><a class="header" href="#24-randomness-in-alephbft">2.4 Randomness In AlephBFT.</a></h3>
<p>One of the differences between the paper and the AlephBFT implementation is in the use of randomness. The AlephBFT protocol in the paper uses randomness in two parts:</p>
<ol>
<li>The <code>CommonVote(round_diff)</code> for <code>round_diff &gt;= 5</code> is not deterministic, but is a random bit that is obtained from a seed that is generated as part of the protocol execution specifically for the unit <code>U</code> the CommonVote concerns (thus in particular the <code>CommonVote</code> function takes a unit <code>U</code> as an additional parameter).</li>
<li>The ordering over units in <code>Head(r, D)</code> is also random and seed is generated specifically for the round <code>r</code>.</li>
</ol>
<p>The corresponding seeds are generated with an appropriate timing, so that the randomness cannot be predicted well in advance. In the AlephBFT implementation both the common votes and the permutation of units are deterministic. The consequence of this is that the version of the protocol implemented in AlephBFT does not have the theoretical property called <em>Asynchronous Liveness</em>. This property means that in a theoretical scenario when the whole network is under control of a powerful adversary, who can schedule all the packets (even from honest nodes) according to its liking, the protocol should still make progress in producing the output stream. That being said there are two important comments to be made here:</p>
<ul>
<li>Even without randomness AlephBFT is <em>Asynchronously Safe</em> and enjoys all the properties of the state-of-the art partially synchronous protocols such as <em>HotStuff</em>, <em>Tendermint</em> or <em>Streamlet</em>. Moreover the asynchronous design of the protocol makes AlephBFT especially robust and resistant against practical network issues that classical partially synchronous protocols might have troubles with. Asynchronous liveness is an important theoretical property and there is a lot of technical sophistication that comes in the design of the protocol in order to achieve it, however on the practical side there is still little evidence that performing such attacks against liveness in real-world scenarios is possible.</li>
<li>Still, no matter how unlikely such attacks might be, we take them very seriously and plan to add randomness to AlephBFT in one of the future releases. We decided to go for a version without randomness first, as it gives an incredibly simple and at the same time secure and robust BFT consensus protocol. Adding randomness introduces some complexity into the protocol, so it makes sense to add it on top of a well-tested, working product. The API of the protocol will not change and we will make the use of randomness configurable.</li>
</ul>
<h3 id="25-alerts----dealing-with-fork-spam"><a class="header" href="#25-alerts----dealing-with-fork-spam">2.5 Alerts -- Dealing with Fork Spam.</a></h3>
<p>We note that the <code>OrderData</code> algorithm as described in previous subsections <strong>is resistant to forks</strong>, meaning that as long as there are at most <code>f</code> forking nodes, then the resulting consensus protocol is still safe.
That being said, there are <strong>practical</strong> issues when it comes to dealing with huge amounts of forks. These are extensively described in the <a href="https://arxiv.org/abs/1908.05156">paper</a> in the section on a &quot;Fork Bomb Attack&quot; -- we encourage the reader to take a look. We describe here a mitigation to this issue that is implemented in AlephBFT. It is based on the idea of &quot;Alerts&quot;, described in the paper, but significantly simplified and made viable for implementation.</p>
<p>The main idea here is that we cannot afford to store an arbitrary amount of units that are forks -- most of them are useless, but without adding a specific mechanism to the protocol, there is no way to discard them. That's why we introduce <strong>Fork Alerts</strong>. A fork alert is a message</p>
<p><strong><code>ForkAlert(sender, forker, proof, units)</code></strong></p>
<p>where <code>sender</code> is the node index of the sender, <code>forker</code> is the node index of a forking node, <code>proof</code> is a pair of units created by forker that constitute a fork and <code>units</code> is simply some list of forker's units. Such a message is brodcast by <code>sender</code> to all other nodes:</p>
<ol>
<li>The broadcast is performed using a <strong>Reliable Broadcast</strong> primitive. Roughly speaking, this means that the node does not simply multicast this message to all the nodes but runs a specialized protocol that guarantees that all the nodes receive this message (if the sender is honest) and receive the exact same version of this message (even if the sender is <strong>dishonest</strong>). We give more details on the AlephBFT's implementation of reliable broadcast in the <a href="reliable_broadcast.html##6-reliable-broadcast">Reliable Broadcast</a> section.</li>
<li>The intuitive meaning of such an alert is that: &quot;I, <code>sender</code>, am aware that <code>forker</code> forked and I attach a <code>proof</code> of that. Moreover, before I realized this fact, I accepted the following list of units from <code>forker</code> to my local copy of the Dag. Please accept these units as well.&quot;</li>
<li>Each sender can send at most one alert regarding a specific <code>forker</code>. So in the worst case, sender would send roughly <code>f</code> alerts.</li>
<li>Each node, right after it realizes about a new node forking, sends its own alert right away, attaching a list of units by forker that it added to its Dag.</li>
<li>The <code>units</code> list cannot contain any forks and must consist of valid units (with correct signatures etc.).</li>
</ol>
<p>Having this mechanism in place we define the (semi-formal) notion of <strong>legit units</strong> as being the ones that are: either from a non-forking node, or were attached to one or more alerts (this notion is not entirely formal because it depends on the timing and on the view of the particular node, but still it carries some useful intuitions). We keep an invariant that</p>
<p><strong>Each honest node adds to its Dag only legit units.</strong></p>
<p>This ensures that there is a reasonable upper bound on the number of units a single node must hold and thus guarantees that AlephBFT will not run out of memory.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="3-api-of-alephbft"><a class="header" href="#3-api-of-alephbft">3 API of AlephBFT</a></h2>
<h3 id="31-required-trait-implementations"><a class="header" href="#31-required-trait-implementations">3.1 Required Trait Implementations.</a></h3>
<h4 id="311-dataprovider--finalizationhandler"><a class="header" href="#311-dataprovider--finalizationhandler">3.1.1 DataProvider &amp; FinalizationHandler.</a></h4>
<p>The DataProvider trait is an abstraction for a component that provides data items. <code>DataProvider</code> is parametrized with a <code>Data</code> generic type representing the type of items we would like to order. Below we give examples of what these might be.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait DataProvider {
    type Output: Data;

    async fn get_data(&amp;mut self) -&gt; Option&lt;Self::Output&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<p>AlephBFT internally calls <code>get_data()</code> whenever a new unit is created and data needs to be placed inside. If no data is currently available, the method should return <code>None</code> immediately to prevent halting unit creation.</p>
<p>The FinalizationHandler trait is an abstraction for a component that should handle finalized items. Same as <code>DataProvider</code> is parametrized with a <code>Data</code> generic type.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait FinalizationHandler&lt;Data&gt; {
    fn data_finalized(&amp;mut self, data: Data);
}
<span class="boring">}
</span></code></pre></pre>
<p>Calls to function <code>data_finalized</code> represent the order of the units that AlephBFT produced and that hold some data.</p>
<h4 id="312-network"><a class="header" href="#312-network">3.1.2 Network.</a></h4>
<p>The Network trait defines the functionality we expect the network layer to satisfy and is quite straightforward:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Network&lt;H: Hasher, D: Data, S: Encode + Decode&gt;: Send {
    fn send(&amp;self, data: NetworkData&lt;H, D, S&gt;, recipient: Recipient);
    async fn next_event(&amp;mut self) -&gt; Option&lt;NetworkData&lt;H, D, S&gt;&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<p>Here <code>NetworkData</code> is a type representing possible network messages for the AlephBFT protocol. For the purpose of implementing the Network trait what matters the most is that they implement the <code>Encode</code> and <code>Decode</code> traits, i.e., allow for serialization/deserialization thus can be treated as byte arrays if that is more convenient. The <code>Recipient</code> represents who should receive the message, either everyone or a node with a specific index:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Recipient {
    Everyone,
    Node(NodeIndex),
}
<span class="boring">}
</span></code></pre></pre>
<p>Additionally <code>NetworkData</code> implements a <code>included_data</code> method which returns all the <code>Data</code> that might end up ordered as a result of this message being passed to AlephBFT. The implementation of <code>Network</code> should ensure that the user system is ready to have that <code>Data</code> be ordered. In the case of <code>Data</code> only representing actual data being ordered (e.g. hashes of blocks of transactions), this means ensuring data availability before passing the messages on.</p>
<p>The <code>send</code> method has straightforward semantics: sending a message to a single or to all the nodes. <code>next_event</code> is an asynchronous method for receiving messages from other nodes.</p>
<p><strong>Note on Rate Control</strong>: it is assumed that Network <strong>implements a rate control mechanism</strong> guaranteeing that no node is allowed to spam messages without limits. We do not specify details yet, but in future releases we plan to publish recommended upper bounds for the amounts of bandwidth and number of messages allowed per node per a unit of time. These bounds must be carefully crafted based upon the number of nodes <code>N</code> and the configured delays between subsequent Dag rounds, so that at the same time spammers are cut off but honest nodes are able function correctly within these bounds.</p>
<p><strong>Note on Network Reliability</strong>: it is not assumed that each message that AlephBFT orders to send reaches its intended recipient, there are some built-in reliability mechanisms within AlephBFT that will automatically detect certain failures and resend messages as needed. Clearly, the less reliable the network is, the worse the performance of AlephBFT will be (generally slower to produce output). Also, not surprisingly if the percentage of dropped messages is too high AlephBFT might stop making progress, but from what we observe in tests, this happens only when the reliability is extremely bad, i.e., drops below 50% (which means there is some significant issue with the network).</p>
<h4 id="313-keychain"><a class="header" href="#313-keychain">3.1.3 Keychain.</a></h4>
<p>The <code>Keychain</code> trait is an abstraction for digitally signing arbitrary data and verifying signatures created by other nodes.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Keychain: Index + Clone + Send + Sync + 'static {
    type Signature: Signature;
    fn sign(&amp;self, msg: &amp;[u8]) -&gt; Self::Signature;
    fn verify(&amp;self, msg: &amp;[u8], sgn: &amp;Self::Signature, index: NodeIndex) -&gt; bool;
}
<span class="boring">}
</span></code></pre></pre>
<p>A typical implementation of Keychain would be a collection of <code>N</code> public keys, an index <code>i</code> and a single private key corresponding to the public key number <code>i</code>. The meaning of <code>sign</code> is then to produce a signature using the given private key, and <code>verify(msg, s, j)</code> is to verify whether the signature <code>s</code> under the message <code>msg</code> is correct with respect to the public key of the <code>j</code>th node.</p>
<h4 id="314-read--write--recovering-mid-session-crashes"><a class="header" href="#314-read--write--recovering-mid-session-crashes">3.1.4 Read &amp; Write – recovering mid session crashes</a></h4>
<p>The <code>std::io::Write</code> and <code>std::io::Read</code> traits are used for creating backups of Units created in a session. This is a part of crash recovery. Units created are needed for member to recover after crash during a session for Aleph to be BFT. This means that user needs to provide two traits <code>std::io::Write</code> and <code>std::io::Read</code> that are used for storing and reading Unit that are processed during operation. At first (without any crash) <code>std::io::Read</code> should return nothing. After crash it should contain all data that was stored before in this session.</p>
<p>These traits are optional. If you do not want to recover crashes mid session or your session handling ensures AlephBFT will not run in the same session twice you can pass NOOP implementation here.</p>
<p><a href="https://doc.rust-lang.org/std/io/trait.Write.html#"><code>std::io::Write</code></a> should provide a way of writing data generated during session which should be backed up. <strong><code>flush</code> method should block until the written data is backed up.</strong></p>
<p><a href="https://doc.rust-lang.org/std/io/trait.Read.html#"><code>std::io::Read</code></a> should provide a way of retreiving backups of all data generated during session by this member in case of crash. <strong><code>std::io::Read</code> should have a copy of all data so that writing to <code>std::io::Write</code> has no effect on reading.</strong></p>
<h3 id="32-examples"><a class="header" href="#32-examples">3.2 Examples</a></h3>
<p>While the implementations of <code>Keychain</code>, <code>std::io::Write</code>, <code>std::io::Read</code> and <code>Network</code> are pretty much universal, the implementation of <code>DataProvider</code> and <code>FinalizationHandler</code> depends on the specific application. We consider two examples here.</p>
<h4 id="321-blockchain-finality-gadget"><a class="header" href="#321-blockchain-finality-gadget">3.2.1 Blockchain Finality Gadget.</a></h4>
<p>Consider a blockchain that does not have an intrinsic finality mechanism, so for instance it might be a PoW chain with probabilistic finality or a chain based on PoS that uses some probabilistic or round-robin block proposal mechanism. Each of the <code>N</code> nodes in the network has its own view of the chain and at certain moments in time there might be conflicts on what the given nodes consider as the &quot;tip&quot; of the blockchain (because of possible forks or network delays). We would like to design a finality mechanism based on AlephBFT that will allow the nodes to have agreement on what the &quot;tip&quot; is. Towards this end we just need to implement a suitable <code>DataProvider</code> object and filtering of network messages for AlephBFT.</p>
<p>For concreteness, suppose each node holds the genesis block <code>B[0]</code> and its hash <code>hash(B[0])</code> and treats it as the highest finalized block so far.</p>
<p>We start by defining the <code>Data</code> type: this will be simply <code>Hash</code> representing the block hash in our blockchain. Subsequently, we implement <code>get_data</code> (note that we use pseudocode instead of Rust, for clarity)</p>
<pre><code>def get_data():
	let B be the tip of the longest chain extending from the most recently finalized block
	return Some(hash(B))
</code></pre>
<p>This is simply the hash of the block the node thinks is the current &quot;tip&quot;.</p>
<p>Using the <code>included_data</code> method of <code>NetworkData</code> we can filter incoming network messages in our implementation of <code>Network</code>. The code handling incoming network messages could be</p>
<pre><code>def handle_incoming_message(M):
 let hashes = M.included_data()
 if we have all the blocks referred to by hashes:
	 if we have all the ancestors of these blocks:
			add M to ready_messages
			return
	add M with it's required hashes to waiting_messages
	request all the blocks we don't have from random nodes
</code></pre>
<p>We note that availability of a block alone is not quite enough for this case as, for instance, if the parent of a block is missing from out storage, we cannot really think of the block as available because we cannot finalize it.</p>
<p>When we get a new block we can check all the messages in <code>wating_messages</code> and move the ones that now have all the hashes satisfied into <code>ready_messages</code>.</p>
<pre><code>def handle_incoming_block(B):
	block_hash = hash(B)
	for M in waiting_messages:
		if M depends on block_hash:
			remove the dependency
			if we don't have an ancestor B' of B:
				add a dependency on hash(B') and request it from random nodes
			if M has no more dependencies:
				move M to ready_messages
</code></pre>
<p>The <code>next</code> method of <code>Network</code> simply returns messages from <code>ready_messages</code>.</p>
<p>Now we can implement handling block finalization by implementing trait <code>FinalizationHandler</code>.</p>
<pre><code>def data_finalized(block_hash):
	let finalized = the highest finalized block so far
 // We have this block in local storage by the above filtering.
    let B be the block such that hash(B) == block_hash
    if finalized is an ancestor of B:
        finalize all the blocks on the path from finalized to B
</code></pre>
<p>Since (because of AlephBFT's guarantees) all the nodes locally observe hashes in the same order, the above implies that all the nodes will finalize the same blocks, with the only difference being possibly a slight difference in timing.</p>
<h4 id="322-state-machine-replication-standalone-blockchain"><a class="header" href="#322-state-machine-replication-standalone-blockchain">3.2.2 State Machine Replication (Standalone Blockchain).</a></h4>
<p>Suppose the set of <code>N</code> nodes would like to implement State Machine Replication, so roughly speaking, a blockchain. Each of the nodes keeps a local transaction pool: transactions it received from users, and the goal is to keep producing blocks with transactions, or in other words produce a linear ordering of these transactions. As previously, we demonstrate how one should go about implementing the <code>DataProvider</code> and <code>FinalizationHandler</code> objects for this application.</p>
<p>First of all, <code>Data</code> in this case is <code>Vec&lt;Transaction&gt;</code>, i.e., a list of transactions.</p>
<pre><code>def get_data():
	tx_list = []
	while tx_pool.not_empty() and tx_list.len() &lt; 100:
		tx = tx_pool.pop()
		tx_list.append(tx)
	return Some(tx_list)
</code></pre>
<p>We simply fetch at most 100 transactions from the local pool and return such a list of transactions.</p>
<pre><code>def data_finalized(tx_list):
	let k be the number of the previous block
	remove duplicated from tx_list
	remove from tx_list all transactions that appeared in blocks B[0], B[1], ..., B[k]
	form block B[k+1] using tx_list as its content
	add B[k+1] to the blockchain
</code></pre>
<p>Whenever a new batch is received we simply create a new block out of the batch's content.</p>
<p>When it comes to availability, in this case <code>Data</code> is not a cryptographic fingerprint of data, but the data itself, so no filtering of network messages is necessary. However, they can be inspected to precompute some operations as an optimization.</p>
<h3 id="33-guarantees-of-alephbft"><a class="header" href="#33-guarantees-of-alephbft">3.3 Guarantees of AlephBFT.</a></h3>
<p>Let <code>round_delay</code> be the average delay between two consecutive rounds in the Dag that can be configured in AlephBFT (default value: 0.5 sec). Under the assumption that there are at most <code>floor(N/3)</code> dishonest nodes in the committee and the network behaves reasonably well (we do not specify the details here, but roughly speaking, a weak form of partial synchrony is required) AlephBFT guarantees that:</p>
<ol>
<li>Each honest node will make progress in producing to the <code>out</code> stream at a pace of roughly <code>1</code> ordered batch per <code>round_delay</code> seconds (by default, two batches per second).</li>
<li>For honest nodes it is guaranteed that the data items they input in the protocol (from their local <code>DataProvider</code> object) will have <code>FinalizationHandler::data_finalized</code> called on them, usually with a delay of roughly <code>~round_delay*4</code> from the time of inputting it.</li>
</ol>
<h3 id="331-what-happens-when-not-enough-nodes-are-honest"><a class="header" href="#331-what-happens-when-not-enough-nodes-are-honest">3.3.1 What happens when not enough nodes are honest.</a></h3>
<p>If there are less than <code>floor(2/3N)+1</code> nodes that are online and are honestly following the protocol rules then certain failures might happen. There are two possibilities:</p>
<ol>
<li><strong>Stall</strong> -- the output streams of nodes stop producing data items. This is also what will happen when the nodes are generally honest, but there is either a significant network partition or lots of nodes crash. If this is not caused by malicious behavior but network issues, the protocol will recover by itself and eventually resume its normal execution.</li>
<li><strong>Inconsistent Output</strong> -- this is the most extreme failure that can happen and can only be a result of malicious behavior of a significant fraction of all the nodes. It means that the honest nodes' output streams stop being consistent. In practice for this to happen the adversary must control <em>lots</em> of nodes, i.e., around <code>(2/3)N</code>. The type of failure that would usually happen if the adversary controls barely above <code>floor(1/3N)+1</code> is stall.</li>
</ol>
<h3 id="34-alephbft-sessions"><a class="header" href="#34-alephbft-sessions">3.4 AlephBFT Sessions.</a></h3>
<p>Currently the API of AlephBFT allows to run a single Session that is expected to last a fixed number of rounds and thus to finalize a fixed number of output batches. By default a AlephBFT Session is <code>5000</code> rounds long but out of these <code>5000</code> there are <code>3000</code> rounds that the protocol proceeds at a regular speed (i.e., <code>500ms</code> per round) and after that starts to slow down (each round is <code>1.005</code> times slower than the previous one) so that round <code>5000</code> is virtually impossible to reach.</p>
<p>There are essentially two ways to use AlephBFT:</p>
<ol>
<li><strong>Single Session</strong> -- just run a single session to make consensus regarding some specific one-time question. In this case one can run the default configuration and just terminate the protocol once the answer is in the output stream.</li>
<li><strong>Multiple Sessions</strong> -- a mode of execution when AlephBFT is run several times sequentially. An important motivating example is the use of AlephBFT as a finality gadget for a blockchain. Think of session <code>k</code> as being responsible for finalizing blocks at heights <code>[100k, 100(k+1)-1]</code>. There should be then an external mechanism to run a new AlephBFT session when the last block of a session gets finalized (and stop inactive sessions as well). This example gives a clear answer for why we opted for the slowdown after round <code>3000</code> as explained above: this is to make sure that no matter the variance in block-time of the block production mechanism, and no matter whether there are stalls, network issues, crashes, etc it is guaranteed that the prespecified segment of blocks will be finalized in a given session. Readers who are experienced with consensus engines are surely aware of how problematic it would be if at the end of a session, say, only <code>70</code> out of the intended <code>100</code> blocks would be finalized. That's why it's better to slow down consensus but make sure it achieves the intended goal.</li>
</ol>
<p><strong>Why are there even sessions in AlephBFT?</strong> To answer this question one would need to make a deep dive into the internal workings of AlephBFT, but a high level summary is: we want to make AlephBFT blazing fast, hence we need to keep everything in RAM (no disk), hence we need to have a round limit, hence we need sessions. For every &quot;hence&quot; in the previous sentence there are extensive arguments to back it, but they are perhaps beyond the scope of this document. We are aware of the inconvenience that it brings -- being forced to implement a session manager, but:</p>
<ol>
<li>We feel that depending on the application there might be different ways to deal with sessions and its better if we leave the task of session managing to the user.</li>
<li>In one of the future releases we plan to add an optional default session manager, but will still encourage the user to implement a custom one for a particular use-case.</li>
</ol>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="4-differences-between-the-implementation-and-the-paper"><a class="header" href="#4-differences-between-the-implementation-and-the-paper">4 Differences between the implementation and the paper.</a></h2>
<p>There are several differences between the Aleph as described in the <a href="https://arxiv.org/abs/1908.05156">paper</a> and the version implemented in AlephBFT. Many of them are already described in previous sections but for completeness we briefly list the differences here.</p>
<ol>
<li>The main version of Aleph uses Reliable Broadcast to disseminate units. The AlephBFT implementation is closer to QuickAleph (in the Appendix of the paper) that uses Reliable Broadcast only for Alerts.</li>
<li>The specifics of alerts are different in the AlephBFT implementation -- in particular they do not require to freeze the protocol at any moment and are generally simpler.</li>
<li>AlephBFT uses its own variant of Reliable Broadcast -- see the section <a href="reliable_broadcast.html##reliable-broadcast">Reliable Broadcast</a>.</li>
<li>Differences in the use of randomness -- see <a href="how_alephbft_does_it.html#24-randomness-in-alephbft">Randomness in AlephBFT</a>.</li>
<li>The main version in the paper uses a full list of parent hashes instead of control hashes -- the latter is described in the Appendix as an optimization.</li>
<li>The paper's Appendix proposes the use of random gossip as a method of disseminating units -- AlephBFT uses repeated broadcast + a request/response mechanism instead, which according to our experience performs much better in practice.</li>
</ol>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="5-alephbft-internals"><a class="header" href="#5-alephbft-internals">5 AlephBFT Internals</a></h2>
<p>To explain the inner workings of AlephBFT it is instructive to follow the path of a unit: from the very start when it is created to the moment when its round is decided and its data is placed in one of the output batches. Here we give a brief overview and subsequently go more into details of specific components in dedicated subsections.</p>
<ol>
<li>The unit is created by one of the node's <code>Creator</code> component -- implemented in <code>creation/</code>. Creator sends the produced unit to <code>consensus/</code>.</li>
<li>A recurring task of broadcasting this unit is put in the task queue. The unit will be broadcast to all other nodes a few times (with some delays in between).</li>
<li>The unit is received by another node -- happens in <code>consensus/</code>, where it is send for further processing in <code>dag/</code>.</li>
<li>Dag validates and reconstructs a unit's parents in several steps:</li>
<li>Validation, implemented in <code>dag/validation.rs</code>, checks signatures and basic unit properties, plus catches forks. This means that only <strong>legit units</strong>, in the sense defined in <a href="how_alephbft_does_it.html#25-alerts----dealing-with-fork-spam">the section on alerts</a>, are sent further. Thus no fork is ever passed on unless coming from an alert.</li>
<li>The units are further moved to a component responsible for reconstructing the explicit parents for these units -- implemented in <code>dag/reconstruction/parents.rs</code>.</li>
<li>Each unit whose parents are successfully decoded, is passed on to <code>dag/reconstruction/dag.rs</code>, which ensures that units are passed on only when their parents already were. They are then returned back to <code>consensus/</code>.</li>
<li>In <code>consensus/</code> such units are put in a store. Each unit in the store is legit + has all its parents in the store.</li>
<li>Such units are passed to a component called the <code>Extender</code> -- see the files in <code>extension/</code>. The role of the extender is to efficiently run the <code>OrderData</code> algorithm, described in the <a href="how_alephbft_does_it.html">section on AlephBFT</a>.</li>
<li>Once a unit's data is placed in one of batches by the <code>Extender</code> then its path is over, although we keep it in the consensus store to be able to send it to other nodes on request.</li>
</ol>
<p>The above description omits backup saving for simplicity. It is injected just before a unit is placed in the store or broadcast.</p>
<h3 id="51-creator"><a class="header" href="#51-creator">5.1 Creator</a></h3>
<p>The creator produces units according to the AlephBFT protocol rules. It will wait until the prespecified delay has passed and attempt to create a unit using a maximal number of parents. If it is not possible yet, it will wait till the first moment enough parents are available. After creating the last unit, the creator stops producing new ones, although this is never expected to happen during correct execution.</p>
<h3 id="52-dag"><a class="header" href="#52-dag">5.2 Dag</a></h3>
<p>The dag receives units from the network and returns any that were successfully reconstructed with parents. It does that in several steps, starting with validation.</p>
<h4 id="521-validation"><a class="header" href="#521-validation">5.2.1 Validation</a></h4>
<p>The validation process consists of checking basic properties of units (correct number of parents, correct session etc.), the signatures, and whether the unit is a fork based on the units that the node either already has or at least started processing. As mentioned, the idea is that only legit units are passed to the reconstructing component. In case a fork by a node <code>i</code> is detected, all of <code>i</code>'s units are attached to the appropriate alert, so that other nodes can accept them as legit.</p>
<p>The next step is to reconstruct the structure of the Dag from the somewhat compressed information in the units.</p>
<h4 id="522-parents"><a class="header" href="#522-parents">5.2.2 Parents</a></h4>
<p>The reconstruction service receives legit units, but the information about their parents is only present as a control hash, i.e. which nodes created the parents and what was the combined hash of all the parents' hashes. Parents reconstruction remembers the first unit for any creator-round combination it encounters and optimistically uses this information to check the combined hash. If there are no dishonest nodes, which is the usual situation, then this means that every unit might at most have some parents that cannot yet be checked, because the node has not yet received them. In such a case requests for these missing units are sent to <code>consensus</code>. After the units are received, the control hash check succeeds and thus the parents are reconstructed successfully.</p>
<p>If dishonest nodes participate in the protocol, then two additional things can go wrong:</p>
<ol>
<li>either the unit has one or multiple parents that are forks, with variants different from the first ones received by this node to be precise. The reconstructing service might or might not have access to the correct variants, but in either case it does not attempt to perform the naive check on different variants -- guessing the correct variants might require exponential time so there is no point to even try it,</li>
<li>or the unit's creator is dishonest and just put a control hash in the unit that does not &quot;unhash&quot; to anything meaningful.</li>
</ol>
<p>In any case the reconstruction triggers a request to <code>consensus</code> to download the full list of the unit's parent hashes, so that the ambiguity is resolved. Once a response is received by <code>consensus</code> then it is passed back to the reconstruction so that it can &quot;decode&quot; the parents and proceed.</p>
<h4 id="523-dag"><a class="header" href="#523-dag">5.2.3 Dag</a></h4>
<p>The units parents might, for many reasons, not be reconstructed in an order agreeing with the Dag order, i.e. some of their ancestors might not yet be reconstructed. The Dag component ensures that units are only added to the store after their parents were already added, and thus any units emitted by the Dag component are in an order agreeing with the Dag order.</p>
<h3 id="53-extender"><a class="header" href="#53-extender">5.3 Extender</a></h3>
<p>The <code>Extender</code>'s role is to receive Dag units (in an order agreeing with the Dag order) and extend the output stream. Towards this end it elects the <code>Head</code> for each <code>round</code>. Such an election works by going through candidate units from this round either eliminating them or eventually electing one. Votes are computed and cached for each candidate until a decision on it is made, after which the election moves on to the next round (if elected as <code>Head</code>) or to the next unit (otherwise). After electing every <code>Head</code> the <code>Extender</code> deterministically orders all its unordered ancestors and the <code>Head</code> itself and returns the resulting batch.</p>
<div id="chapter_begin" style="break-before: page; page-break-before: always;"></div><h2 id="6-reliable-broadcast"><a class="header" href="#6-reliable-broadcast">6 Reliable Broadcast</a></h2>
<p>Recall that Reliable Broadcast is the primitive we use to broadcast <code>fork alerts</code> among nodes -- see <a href="how_alephbft_does_it.html#25-alerts----dealing-with-fork-spam">the section on alerts</a>. There are two requirements for a protocol realizing reliable broadcast:</p>
<ol>
<li>If an honest sender initiates a reliable broadcast with some message <code>m</code> then the protocol terminates and as a result all honest nodes receive <code>m</code>.</li>
<li>If a malicious sender initiates a reliable broadcast then either it terminates for all honest nodes and they receive the same message <code>m</code>, or it does not terminate for any honest node.</li>
</ol>
<p>So, roughly speaking, we want a broadcast primitive that is consistent even if a malicious node is the sender. There is the possibility that a malicious broadcast will not terminate, but it is not hard to see that this is the best we can hope for.</p>
<h3 id="61-consistent-broadcast-using-multisignatures----rmc"><a class="header" href="#61-consistent-broadcast-using-multisignatures----rmc">6.1 Consistent Broadcast using multisignatures -- RMC</a></h3>
<p>The main idea behind the reliable broadcast implementation in AlephBFT is the use of multisignatures. Without going too much into details, think of a multisignature over a message <code>m</code> as a list of <code>N-f</code> signatures by <code>N-f</code> different committee nodes over the same message <code>m</code> (more efficient ways to achieve such a functionality are possible, like threshold signatures or signature aggregates, but they are beyond the scope of this section). Someone holding a multisignature over <code>m</code> can be sure that a large fraction of nodes &quot;agree&quot; (with the meaning of &quot;agree&quot; depending on the particular application) on <code>m</code>.</p>
<p>The RMC (Reliable MultiCast) protocol is a way to reliably disseminate a single hash <code>h</code> among all nodes (in the next section we explain how to extend it to disseminating arbitrary data and not only a hash). The idea is as follows:</p>
<ol>
<li>Whenever a node <code>i</code> wishes to disseminate a hash <code>h</code> it initiates a reliable multicast instance by signing <code>h</code> and sending such a signed hash <code>SIG(h, i, sig_i)</code> to all other nodes.</li>
<li>Upon receiving such a signed hash, each node <code>j</code> signs <code>h</code> and sends its signed hash: <code>SIG(h, j, sig_j)</code> to all other nodes.</li>
<li>Each node keeps receiving signatures under <code>h</code> from different nodes. Upon receiving <code>N-f</code> of them, this node combines the signatures into a single multisignature <code>msig</code> and sends to all nodes a message <code>MULTISIG(h, msig)</code>.</li>
<li>Upon receiving <code>MULTISIG(h, msig)</code> under <code>h</code>, each node passes it also to all other nodes.</li>
</ol>
<p>The moment when a node receives <code>MULTISIG(h, msig)</code> is considered as the completion of the multicast for this node (and even though the node still keeps resubmitting messages) this instance of RMC is considered as successful. If a RMC succeeds for some honest node then it is guaranteed to succeed for all honest nodes (but maybe with some delay). We refer to the file <code>/src/rmc.rs</code> for a thorough documentation of this component.</p>
<h3 id="62-reliable-broadcast-based-on-rmc"><a class="header" href="#62-reliable-broadcast-based-on-rmc">6.2 Reliable Broadcast based on RMC</a></h3>
<p>Having the idea of RMC, one can modify it quite easily to achieve reliable broadcast. A naive way to do so would be to let the sender node hash the message <code>m</code> it intends to reliably broadcast into <code>h=hash(m)</code> and use RMC on the hash <code>h</code>. This almost works, except for the data availability problem -- a malicious sender might simply send a random meaningless hash <code>h</code> and then the honest nodes would never be able to recover the underlying data.</p>
<p>To circumvent the data availability problem we instruct the sender to send data <code>m</code> to all the nodes and only then to initiate RMC on <code>h = hash(m)</code>, if we make sure that no honest node proceeds with RMC before it receives the data <code>m</code>, then a successful RMC has the guarantee that most of the honest nodes hold the data <code>m</code>. This is the basic idea behind the protocol implemented for fork alerts in AlephBFT, we refer to <code>/src/alerts.rs</code> for details.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
